{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4fb80f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp=spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1202d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural\n",
      "Language\n",
      "Processing\n",
      "with\n",
      "Python\n",
      "is\n",
      "fun\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "# Ques-1- Tokenize a simple sentence using word_tokenize. ( \"Natural Language Processing with Python is fun.\")\n",
    "word_tokenize = nlp(\"Natural Language Processing with Python is fun.\")\n",
    "for t in word_tokenize:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0499481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import string\n",
    "string.punctuation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91f3bb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello there Hows the weather today\n"
     ]
    }
   ],
   "source": [
    "# Ques-2-punctuation from a sentence using NLTK. (\"Hello there! How's the weather today?\").\n",
    "exclude = string.punctuation\n",
    "def remove_punc(text):\n",
    "    for char in exclude:\n",
    "        text = text.replace(char,'')\n",
    "    return text\n",
    "text = \"Hello there! How's the weather today?\"\n",
    "print(remove_punc(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84905cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This simple sentence stopword removal.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "# Ques-3-`Remove stopwords from a sentence. (\"This is a simple sentence for stopword removal.\")\n",
    "def remove_stopwords(text):\n",
    "    new_text = []\n",
    "    for word in text.split():\n",
    "        if word not in stopwords.words('english'):\n",
    "            new_text.append(word)\n",
    "    return \" \".join(new_text)\n",
    "remove_stopwords(\"This is a simple sentence for stopword removal.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50892cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the stripe bat are hang on their feet for best.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "# Ques-4-Perform stemming using PorterStemmer. (\"The striped bats are hanging on their feet for best.\")\n",
    "ps = PorterStemmer()\n",
    "def stem_words(text):\n",
    "    return \" \".join([ps.stem(word) for word in text.split()])\n",
    "sample = \"The striped bats are hanging on their feet for best.\"\n",
    "stem_words(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e2a769c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                Lemma               \n",
      "The                 The                 \n",
      "geese               goose               \n",
      "are                 are                 \n",
      "flying              flying              \n",
      "south               south               \n",
      "for                 for                 \n",
      "the                 the                 \n",
      "winter              winter              \n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# Ques-5-Perform lemmatization using WordNetLemmatizer. (\"The geese are flying south for the winter.\")\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "sentence = \"The geese are flying south for the winter.\"\n",
    "punctuations = \"?:!.,;\"\n",
    "sentence_words = nltk.word_tokenize(sentence)\n",
    "for word in sentence_words:\n",
    "    if word in punctuations:\n",
    "        sentence_words.remove(word)\n",
    "sentence_words\n",
    "print(\"{0:20}{1:20}\".format(\"Word\",\"Lemma\"))\n",
    "for word in sentence_words:\n",
    "    print(\"{0:20}{1:20}\".format(word,wordnet_lemmatizer.lemmatize(word)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "60acd117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello, world! nlp with python.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ques-6-Convert text to lowercase and remove punctuation. (\"Hello, World! NLP with Python.\")\n",
    "text = \"Hello, World! NLP with Python.\"\n",
    "text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "78878a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World NLP with Python\n"
     ]
    }
   ],
   "source": [
    "# Removing Punction\n",
    "exclude = string.punctuation\n",
    "def remove_punc(text):\n",
    "    for char in exclude:\n",
    "        text = text.replace(char,'')\n",
    "    return text\n",
    "text = \"Hello, World! NLP with Python.\"\n",
    "print(remove_punc(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "deb59b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "import  nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1880e91e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello World.', 'This is NLTK.', \"Let's explore NLP!\"]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ques-7-Tokenize a sentence into sentences using sent_tokenize. (\"Hello World. This is NLTK. Let's explore NLP!\")\n",
    "doc1 = \"Hello World. This is NLTK. Let's explore NLP!\"\n",
    "sent_tokenize(doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "900b4e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loving the experience of learning NLTK --> loving the experience of learning nltk\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "# Ques-8-Stem words in a sentence using LancasterStemmer. (“Loving the experience of learning NLTK”)\n",
    "l_stemmer = LancasterStemmer()\n",
    "text1 = ['Loving the experience of learning NLTK']\n",
    "         \n",
    "for word in text1:\n",
    "    print(word+' --> '+l_stemmer.stem(word))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b5467848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This test sentence, stopwords punctuation!'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ques-9-Remove both stopwords and punctuation from a sentence. (\"This is a test sentence, with stopwords and punctuation!\")\n",
    "def remove_stopwords(text):\n",
    "    new_text = []\n",
    "    for word in text.split():\n",
    "        if word not in stopwords.words('english'):\n",
    "            new_text.append(word)\n",
    "    return \" \".join(new_text)\n",
    "remove_stopwords(\"This is a test sentence, with stopwords and punctuation!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fea3ad06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a test sentence with stopwords and punctuation\n"
     ]
    }
   ],
   "source": [
    "# Removing Punction\n",
    "exclude = string.punctuation\n",
    "def remove_punc(text):\n",
    "    for char in exclude:\n",
    "        text = text.replace(char,'')\n",
    "    return text\n",
    "text = \"This is a test sentence, with stopwords and punctuation!\"\n",
    "print(remove_punc(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fe8337a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The          DET    7425985699627899538    the\n",
      "striped      VERB   929563449582324419     stripe\n",
      "bats         NOUN   8577633547555682751    bat\n",
      "are          AUX    10382539506755952630   be\n",
      "hanging      VERB   4780549502391586051    hang\n",
      "on           ADP    5640369432778651323    on\n",
      "their        PRON   4244585616942201722    their\n",
      "feet         NOUN   779410287755165804     foot\n",
      ".            PUNCT  12646065887601541794   .\n"
     ]
    }
   ],
   "source": [
    "# Ques-10-Lemmatize words with their part-of-speech (POS) tag. (\"The striped bats are hanging on their feet.\")\n",
    "doc1 = nlp(\"The striped bats are hanging on their feet.\")\n",
    "for token in doc1:\n",
    "    print(f'{token.text:{12}} {token.pos_:{6}} {token.lemma:<{22}} {token.lemma_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a92658b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running\n",
      "through\n",
      "the\n",
      "forest\n",
      ",\n",
      "the\n",
      "fox\n",
      "is\n",
      "faster\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "# Ques-11-Tokenize and remove stopwords, punctuation, and perform stemming. (\"Running through the forest, the fox is faster.\")\n",
    "# Tokenization\n",
    "doc = nlp(\"Running through the forest, the fox is faster.\")\n",
    "for tokens in doc:\n",
    "    print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "824f9e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Running forest, fox faster.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing stop words\n",
    "def remove_stopwords(doc):\n",
    "    new_doc = []\n",
    "    for word in doc.split():\n",
    "        if word not in stopwords.words('english'):\n",
    "            new_doc.append(word)\n",
    "    return \" \".join(new_doc)\n",
    "remove_stopwords(\"Running through the forest, the fox is faster.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e5438ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running through the forest the fox is faster\n"
     ]
    }
   ],
   "source": [
    "# Removing Punctuation\n",
    "exclude = string.punctuation\n",
    "def remove_punc(text):\n",
    "    for char in exclude:\n",
    "        text = text.replace(char,'')\n",
    "    return text\n",
    "text = \"Running through the forest, the fox is faster.\"\n",
    "print(remove_punc(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8fdfc061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running --> run\n",
      "through --> through\n",
      "the --> the\n",
      "forest, --> forest,\n",
      "the --> the\n",
      "fox --> fox\n",
      "is --> is\n",
      "faster. --> faster.\n"
     ]
    }
   ],
   "source": [
    "# Stemming\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "p_stemmer = PorterStemmer()\n",
    "phrase = \"Running through the forest, the fox is faster.\"\n",
    "for word in phrase.split():\n",
    "    print(word+' --> '+p_stemmer.stem(word))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0f18ccbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of stopwords: 4\n"
     ]
    }
   ],
   "source": [
    "# Ques-12-Count stopwords in a sentence. (\"This is an example sentence for counting stopwords.\")\n",
    "stop_words = set(stopwords.words('english'))\n",
    "sentence = \"This is an example sentence for counting stopwords.\"\n",
    "words = sentence.split()\n",
    "stopword_count = 0\n",
    "for word in words:\n",
    "    if word.lower() in stop_words:\n",
    "        stopword_count += 1\n",
    "print(\"No of stopwords:\", stopword_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b0cab6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stem', 'punctuat', 'remov', 'exampl']\n"
     ]
    }
   ],
   "source": [
    "# Ques-13-Perform stemming and remove punctuation using RegexTokenizer. (\"Stemming, punctuation! Removal example.\")\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "stemmer = PorterStemmer()\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "sentence = \"Stemming, punctuation! Removal example.\"\n",
    "words = tokenizer.tokenize(sentence)\n",
    "stemmed_words = [stemmer.stem(word) for word in words]\n",
    "print(stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "249f23fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Punctuation', 'removal', 'with', 'regex', 'in', 'NLP']\n"
     ]
    }
   ],
   "source": [
    "# Ques-14-Remove punctuation using regex and NLTK. (\"Punctuation removal with regex in NLP!\")\n",
    "import re\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "sentence = \"Punctuation removal with regex in NLP!\"\n",
    "words = tokenizer.tokenize(sentence)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f1106450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Punctuation', 'removal', 'with', 'regex', 'in', 'NLP']\n"
     ]
    }
   ],
   "source": [
    "# By using 're' module directly\n",
    "sentence = \"Punctuation removal with regex in NLP!\"\n",
    "words = re.findall(r'\\w+', sentence)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "de7cba0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "475098a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'dog', 'barking', 'loudly', '.']\n"
     ]
    }
   ],
   "source": [
    "# Ques-15-Tokenize text into words, remove stopwords, and lemmatize. (\"The dogs are barking loudly.\")\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "\n",
    "sentence = \"The dogs are barking loudly.\"\n",
    "words = nltk.word_tokenize(sentence)\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "words = [word for word in words if word not in stop_words]\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "print(lemmatized_words)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a967d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
